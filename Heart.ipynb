{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heart.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrandonSin/CPSC501Assignment4/blob/master/Heart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1gCrXSWJMnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCTvjLqFJYRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import functools\n",
        "import sys\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow_core.python.keras import regularizers\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gje0p3es7m80",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "75fc821a-5a5b-414e-da25-19f55129448f"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a39c70ed-2f63-4c3e-ab84-a8ab524d9dfa\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a39c70ed-2f63-4c3e-ab84-a8ab524d9dfa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving heart_test.csv to heart_test.csv\n",
            "Saving heart_train.csv to heart_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ4WVuN1U_VP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = \"heart_train.csv\"\n",
        "test_file = \"heart_test.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2BDJMu6J42R",
        "colab_type": "code",
        "outputId": "7a0bac5f-4f87-4bfe-d896-d5c8bde9132d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "!head {train_file}"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sbp,tobacco,ldl,adiposity,famhist,typea,obesity,alcohol,age,chd\r\n",
            "160,12,5.73,23.11,Present,49,25.3,97.2,52,1\r\n",
            "144,0.01,4.41,28.61,Absent,55,28.87,2.06,63,1\r\n",
            "118,0.08,3.48,32.28,Present,52,29.14,3.81,46,0\r\n",
            "170,7.5,6.41,38.03,Present,51,31.99,24.26,58,1\r\n",
            "134,13.6,3.5,27.78,Present,60,25.99,57.34,49,1\r\n",
            "132,6.2,6.47,36.21,Present,62,30.77,14.14,45,0\r\n",
            "142,4.05,3.38,16.2,Absent,59,20.81,2.62,38,0\r\n",
            "114,4.08,4.59,14.6,Present,62,23.11,6.72,58,1\r\n",
            "114,0,3.83,19.4,Present,49,24.86,2.49,29,0\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01KRV62YJ5bu",
        "colab_type": "code",
        "outputId": "9c2b7ca3-f933-4da4-b2c8-b36b37b7b806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "!head {test_file}"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sbp,tobacco,ldl,adiposity,famhist,typea,obesity,alcohol,age,chd\r\n",
            "160,12,5.73,23.11,Present,49,25.3,97.2,52,1\r\n",
            "144,0.01,4.41,28.61,Absent,55,28.87,2.06,63,1\r\n",
            "118,0.08,3.48,32.28,Present,52,29.14,3.81,46,0\r\n",
            "170,7.5,6.41,38.03,Present,51,31.99,24.26,58,1\r\n",
            "134,13.6,3.5,27.78,Present,60,25.99,57.34,49,1\r\n",
            "132,6.2,6.47,36.21,Present,62,30.77,14.14,45,0\r\n",
            "142,4.05,3.38,16.2,Absent,59,20.81,2.62,38,0\r\n",
            "114,4.08,4.59,14.6,Present,62,23.11,6.72,58,1\r\n",
            "114,0,3.83,19.4,Present,49,24.86,2.49,29,0\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUhMX9n6Z6ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(dataset):\n",
        "  for batch, label in dataset.take(1):\n",
        "    for key, value in batch.items():\n",
        "      print(\"{:20s}: {}\".format(key,value.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zFwz2hibTn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PackNumericFeatures(object):\n",
        "  def __init__(self,names):\n",
        "    self.names = names\n",
        "  \n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC_awOYIbkj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset(file, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file,\n",
        "      batch_size = 50,\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value =\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True,\n",
        "      **kwargs)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A82rug65KeSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLUMN = 'chd'\n",
        "LABELS = [0, 1]\n",
        "\n",
        "CATEGORIES = {'famhist': ['Present', 'Absent']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGiKzLPOKfuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = \"heart_train.csv\"\n",
        "test_data = \"heart_test.csv\"\n",
        "\n",
        "SELECT_COLUMNS = ['sbp','tobacco','ldl','adiposity','famhist', 'typea','obesity','alcohol','age','chd']\n",
        "raw_train_data = get_dataset(train_data, select_columns=SELECT_COLUMNS)\n",
        "raw_test_data = get_dataset(test_data, select_columns=SELECT_COLUMNS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qole6DDLdTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch, label_batch = next(iter(raw_train_data))\n",
        "test_batch, label_batch = next(iter(raw_test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enGCrnE-EvPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzKaCc2ULlGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUMERIC_FEATURES = ['sbp','tobacco','ldl','adiposity', 'typea','obesity','alcohol','age']\n",
        "\n",
        "packed_train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "packed_test_data = raw_test_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMMGtsigLtGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch, label_batch = next(iter(packed_train_data))\n",
        "test_batch, label_batch = next(iter(packed_test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riXRIWkALx2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "33c96437-b40f-4c24-c5ef-b590f90194da"
      },
      "source": [
        "import pandas as pd\n",
        "desc = pd.read_csv(train_data)[NUMERIC_FEATURES].describe()\n",
        "desc"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sbp</th>\n",
              "      <th>tobacco</th>\n",
              "      <th>ldl</th>\n",
              "      <th>adiposity</th>\n",
              "      <th>typea</th>\n",
              "      <th>obesity</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>462.000000</td>\n",
              "      <td>462.000000</td>\n",
              "      <td>462.000000</td>\n",
              "      <td>462.000000</td>\n",
              "      <td>462.000000</td>\n",
              "      <td>462.000000</td>\n",
              "      <td>462.000000</td>\n",
              "      <td>462.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>138.326840</td>\n",
              "      <td>3.635649</td>\n",
              "      <td>4.740325</td>\n",
              "      <td>25.406732</td>\n",
              "      <td>53.103896</td>\n",
              "      <td>26.044113</td>\n",
              "      <td>17.044394</td>\n",
              "      <td>42.816017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>20.496317</td>\n",
              "      <td>4.593024</td>\n",
              "      <td>2.070909</td>\n",
              "      <td>7.780699</td>\n",
              "      <td>9.817534</td>\n",
              "      <td>4.213680</td>\n",
              "      <td>24.481059</td>\n",
              "      <td>14.608956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>6.740000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>124.000000</td>\n",
              "      <td>0.052500</td>\n",
              "      <td>3.282500</td>\n",
              "      <td>19.775000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>22.985000</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>134.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.340000</td>\n",
              "      <td>26.115000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>25.805000</td>\n",
              "      <td>7.510000</td>\n",
              "      <td>45.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>148.000000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>5.790000</td>\n",
              "      <td>31.227500</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>28.497500</td>\n",
              "      <td>23.892500</td>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>218.000000</td>\n",
              "      <td>31.200000</td>\n",
              "      <td>15.330000</td>\n",
              "      <td>42.490000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>46.580000</td>\n",
              "      <td>147.190000</td>\n",
              "      <td>64.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              sbp     tobacco         ldl  ...     obesity     alcohol         age\n",
              "count  462.000000  462.000000  462.000000  ...  462.000000  462.000000  462.000000\n",
              "mean   138.326840    3.635649    4.740325  ...   26.044113   17.044394   42.816017\n",
              "std     20.496317    4.593024    2.070909  ...    4.213680   24.481059   14.608956\n",
              "min    101.000000    0.000000    0.980000  ...   14.700000    0.000000   15.000000\n",
              "25%    124.000000    0.052500    3.282500  ...   22.985000    0.510000   31.000000\n",
              "50%    134.000000    2.000000    4.340000  ...   25.805000    7.510000   45.000000\n",
              "75%    148.000000    5.500000    5.790000  ...   28.497500   23.892500   55.000000\n",
              "max    218.000000   31.200000   15.330000  ...   46.580000  147.190000   64.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmFVmsqmL6FU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])\n",
        "def normalize_numeric_data(data, mean, std):\n",
        "  return (data-mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIG6dDspMHan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8b1KSi7MMBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch['numeric']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7_Sg_x0MODw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "numeric_layer(train_batch).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BXNmG65MXZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pALQEo_jMfuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FC9IMOiMnQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  preprocessing_layer,\n",
        "  layers.Dense(256, activation='relu'),\n",
        "  layers.Dropout(0.7),\n",
        "   layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(0.5),\n",
        "   layers.Dense(128, activation='selu'),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkG6eoWaMqeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_train_data.shuffle(500)\n",
        "test_data = packed_test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6H_AExPMsa5",
        "colab_type": "code",
        "outputId": "e00d25f8-fd54-4b4c-9bd7-cd8f1a8751db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "print(\"--Train--\")\n",
        "model.fit(train_data, epochs=300)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy * 100))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Train--\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.4020 - accuracy: 0.7965\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3902 - accuracy: 0.7944\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3851 - accuracy: 0.7922\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4085 - accuracy: 0.8095\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4015 - accuracy: 0.8247\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3999 - accuracy: 0.8030\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3665 - accuracy: 0.8117\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4119 - accuracy: 0.8052\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8160\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4199 - accuracy: 0.8182\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3853 - accuracy: 0.7987\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3630 - accuracy: 0.8203\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4001 - accuracy: 0.8312\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4155 - accuracy: 0.8052\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3792 - accuracy: 0.8074\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3779 - accuracy: 0.8225\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4069 - accuracy: 0.8052\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4061 - accuracy: 0.8009\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3853 - accuracy: 0.8074\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3687 - accuracy: 0.8355\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3528 - accuracy: 0.8355\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3707 - accuracy: 0.8182\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3792 - accuracy: 0.8117\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3647 - accuracy: 0.8117\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3512 - accuracy: 0.8312\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3437 - accuracy: 0.8355\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3627 - accuracy: 0.8312\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3848 - accuracy: 0.8203\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3763 - accuracy: 0.8117\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3614 - accuracy: 0.8139\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3717 - accuracy: 0.8225\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3753 - accuracy: 0.8268\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3605 - accuracy: 0.8117\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3409 - accuracy: 0.8442\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3647 - accuracy: 0.8333\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3697 - accuracy: 0.8355\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3590 - accuracy: 0.8528\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3534 - accuracy: 0.7965\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3907 - accuracy: 0.8203\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3738 - accuracy: 0.8030\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3468 - accuracy: 0.8463\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4074 - accuracy: 0.8139\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3371 - accuracy: 0.8485\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3519 - accuracy: 0.8420\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3493 - accuracy: 0.8420\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3873 - accuracy: 0.8377\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3964 - accuracy: 0.7965\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3585 - accuracy: 0.8268\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3530 - accuracy: 0.8247\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3545 - accuracy: 0.8095\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3648 - accuracy: 0.8506\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3809 - accuracy: 0.8247\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3325 - accuracy: 0.8485\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3754 - accuracy: 0.8182\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3293 - accuracy: 0.8442\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3739 - accuracy: 0.8139\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3374 - accuracy: 0.8203\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3538 - accuracy: 0.8333\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3881 - accuracy: 0.8203\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3770 - accuracy: 0.8333\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3380 - accuracy: 0.8355\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3456 - accuracy: 0.8355\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3510 - accuracy: 0.8268\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3625 - accuracy: 0.8442\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3636 - accuracy: 0.8333\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3467 - accuracy: 0.8377\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3348 - accuracy: 0.8377\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3407 - accuracy: 0.8312\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3662 - accuracy: 0.8203\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3187 - accuracy: 0.8463\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3580 - accuracy: 0.8225\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3501 - accuracy: 0.8268\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3576 - accuracy: 0.8312\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3296 - accuracy: 0.8463\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3610 - accuracy: 0.8377\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3398 - accuracy: 0.8355\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3466 - accuracy: 0.8463\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3355 - accuracy: 0.8247\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3386 - accuracy: 0.8312\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3163 - accuracy: 0.8571\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3404 - accuracy: 0.8377\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3620 - accuracy: 0.8225\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3175 - accuracy: 0.8485\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3740 - accuracy: 0.8290\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3235 - accuracy: 0.8290\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2886 - accuracy: 0.8485\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2921 - accuracy: 0.8701\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3145 - accuracy: 0.8528\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.8593\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3245 - accuracy: 0.8485\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3365 - accuracy: 0.8442\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2856 - accuracy: 0.8528\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3254 - accuracy: 0.8442\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3679 - accuracy: 0.8442\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3176 - accuracy: 0.8615\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3594 - accuracy: 0.8333\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3395 - accuracy: 0.8355\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3369 - accuracy: 0.8420\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3554 - accuracy: 0.8182\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3415 - accuracy: 0.8593\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3034 - accuracy: 0.8658\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3608 - accuracy: 0.8247\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2901 - accuracy: 0.8528\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3191 - accuracy: 0.8550\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3170 - accuracy: 0.8312\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3547 - accuracy: 0.8355\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3360 - accuracy: 0.8506\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3221 - accuracy: 0.8203\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3162 - accuracy: 0.8312\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3107 - accuracy: 0.8355\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3492 - accuracy: 0.8658\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3335 - accuracy: 0.8615\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2842 - accuracy: 0.8680\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3588 - accuracy: 0.8442\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3093 - accuracy: 0.8593\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3224 - accuracy: 0.8485\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2932 - accuracy: 0.8636\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3284 - accuracy: 0.8593\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2938 - accuracy: 0.8593\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2937 - accuracy: 0.8398\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3389 - accuracy: 0.8766\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3103 - accuracy: 0.8398\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3215 - accuracy: 0.8485\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3371 - accuracy: 0.8333\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3081 - accuracy: 0.8463\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3150 - accuracy: 0.8593\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3214 - accuracy: 0.8485\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3241 - accuracy: 0.8463\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2858 - accuracy: 0.8420\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3569 - accuracy: 0.8485\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3331 - accuracy: 0.8528\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2961 - accuracy: 0.8571\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3098 - accuracy: 0.8571\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3253 - accuracy: 0.8550\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3297 - accuracy: 0.8312\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3152 - accuracy: 0.8593\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3309 - accuracy: 0.8463\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3087 - accuracy: 0.8680\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3008 - accuracy: 0.8571\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3464 - accuracy: 0.8485\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3266 - accuracy: 0.8528\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3044 - accuracy: 0.8506\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3106 - accuracy: 0.8593\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3286 - accuracy: 0.8420\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2878 - accuracy: 0.8593\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2963 - accuracy: 0.8636\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2855 - accuracy: 0.8636\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3177 - accuracy: 0.8485\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2623 - accuracy: 0.8680\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3427 - accuracy: 0.8810\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3270 - accuracy: 0.8593\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2867 - accuracy: 0.8680\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2878 - accuracy: 0.8571\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3381 - accuracy: 0.8398\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3266 - accuracy: 0.8615\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3199 - accuracy: 0.8550\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2984 - accuracy: 0.8788\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2568 - accuracy: 0.8701\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2786 - accuracy: 0.8810\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3158 - accuracy: 0.8658\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3045 - accuracy: 0.8528\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2744 - accuracy: 0.8550\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2906 - accuracy: 0.8658\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2869 - accuracy: 0.8528\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2763 - accuracy: 0.8723\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2924 - accuracy: 0.8723\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2858 - accuracy: 0.8636\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2756 - accuracy: 0.8745\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2831 - accuracy: 0.8701\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2929 - accuracy: 0.8874\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2658 - accuracy: 0.8939\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2433 - accuracy: 0.8745\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2759 - accuracy: 0.8831\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2910 - accuracy: 0.8723\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3017 - accuracy: 0.8723\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2497 - accuracy: 0.8918\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2617 - accuracy: 0.8745\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2892 - accuracy: 0.8745\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2559 - accuracy: 0.8766\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3376 - accuracy: 0.8550\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2736 - accuracy: 0.8874\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2742 - accuracy: 0.8745\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3166 - accuracy: 0.8983\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2840 - accuracy: 0.8745\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2541 - accuracy: 0.8896\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2658 - accuracy: 0.8918\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2626 - accuracy: 0.8658\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2607 - accuracy: 0.8853\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2838 - accuracy: 0.8810\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2651 - accuracy: 0.8874\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2504 - accuracy: 0.8983\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2818 - accuracy: 0.8810\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2882 - accuracy: 0.8896\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2460 - accuracy: 0.9069\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2891 - accuracy: 0.8636\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2299 - accuracy: 0.8918\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2707 - accuracy: 0.8701\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2397 - accuracy: 0.8831\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2817 - accuracy: 0.8788\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8680\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2546 - accuracy: 0.8788\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2406 - accuracy: 0.9048\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2535 - accuracy: 0.9004\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2750 - accuracy: 0.8810\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2157 - accuracy: 0.9004\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2663 - accuracy: 0.8853\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2810 - accuracy: 0.8918\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2291 - accuracy: 0.8961\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2753 - accuracy: 0.8788\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3534 - accuracy: 0.8874\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2461 - accuracy: 0.8918\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2923 - accuracy: 0.8810\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2495 - accuracy: 0.8810\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2785 - accuracy: 0.8701\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2848 - accuracy: 0.8810\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2744 - accuracy: 0.8896\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2570 - accuracy: 0.8896\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2434 - accuracy: 0.9091\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2504 - accuracy: 0.8918\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2430 - accuracy: 0.8939\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2701 - accuracy: 0.8745\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2286 - accuracy: 0.8874\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2861 - accuracy: 0.8766\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2521 - accuracy: 0.8939\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2479 - accuracy: 0.9004\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2717 - accuracy: 0.8766\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2111 - accuracy: 0.9004\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2292 - accuracy: 0.9069\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2743 - accuracy: 0.8896\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2684 - accuracy: 0.8788\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2671 - accuracy: 0.8896\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2675 - accuracy: 0.8766\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2551 - accuracy: 0.8874\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2482 - accuracy: 0.8788\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2578 - accuracy: 0.8831\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2356 - accuracy: 0.8983\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3047 - accuracy: 0.9004\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2020 - accuracy: 0.9048\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2395 - accuracy: 0.8853\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2221 - accuracy: 0.9069\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2385 - accuracy: 0.9113\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2635 - accuracy: 0.8766\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2632 - accuracy: 0.9004\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2452 - accuracy: 0.8874\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2518 - accuracy: 0.8918\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2627 - accuracy: 0.8874\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2105 - accuracy: 0.9113\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2097 - accuracy: 0.9113\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2155 - accuracy: 0.8983\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2088 - accuracy: 0.9091\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2786 - accuracy: 0.8961\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2234 - accuracy: 0.9048\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2676 - accuracy: 0.9048\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2563 - accuracy: 0.8896\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2244 - accuracy: 0.9091\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2265 - accuracy: 0.9026\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2571 - accuracy: 0.9091\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2459 - accuracy: 0.8961\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2293 - accuracy: 0.9048\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2624 - accuracy: 0.8961\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2172 - accuracy: 0.9199\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2235 - accuracy: 0.8961\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2301 - accuracy: 0.9004\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2301 - accuracy: 0.9091\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2019 - accuracy: 0.9113\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2274 - accuracy: 0.9286\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2853 - accuracy: 0.9134\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2369 - accuracy: 0.8983\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2193 - accuracy: 0.9091\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2285 - accuracy: 0.8983\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2097 - accuracy: 0.9242\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2307 - accuracy: 0.9004\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2299 - accuracy: 0.9156\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2173 - accuracy: 0.9177\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1906 - accuracy: 0.9156\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2527 - accuracy: 0.9004\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2346 - accuracy: 0.9026\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2488 - accuracy: 0.9026\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3087 - accuracy: 0.8853\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2299 - accuracy: 0.9069\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2598 - accuracy: 0.8961\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2283 - accuracy: 0.8983\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2304 - accuracy: 0.9134\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2815 - accuracy: 0.8745\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2460 - accuracy: 0.8853\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2611 - accuracy: 0.8810\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2209 - accuracy: 0.9156\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2594 - accuracy: 0.8939\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2625 - accuracy: 0.8810\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2387 - accuracy: 0.8939\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2312 - accuracy: 0.8874\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2317 - accuracy: 0.8983\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1886 - accuracy: 0.9156\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2421 - accuracy: 0.9156\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1870 - accuracy: 0.9351\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2335 - accuracy: 0.8983\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2035 - accuracy: 0.9134\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1990 - accuracy: 0.9113\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2138 - accuracy: 0.9199\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2502 - accuracy: 0.9113\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0996 - accuracy: 0.9859\n",
            "\n",
            "\n",
            "Test Loss 0.09963567927479744, Test Accuracy 98.591548204422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDEbE2CbVZns",
        "colab_type": "code",
        "outputId": "64f9dd0d-500d-478c-b339-2e2b6e91cb39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "# Show some results\n",
        "predictions = model.predict(test_data)\n",
        "for prediction, CHD in zip(predictions[:50], list(test_data)[0][1][:50]):\n",
        "  print(\"Prediction of CGH: {:.2%}\".format(prediction[0]) + \" Actual Outcome: \",\n",
        "        (\"Postive\" if bool(CHD) else \"Negative\"))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction of CGH: 5.60% Actual Outcome:  Negative\n",
            "Prediction of CGH: 6.63% Actual Outcome:  Postive\n",
            "Prediction of CGH: 40.28% Actual Outcome:  Postive\n",
            "Prediction of CGH: 29.44% Actual Outcome:  Negative\n",
            "Prediction of CGH: 22.93% Actual Outcome:  Negative\n",
            "Prediction of CGH: 70.20% Actual Outcome:  Negative\n",
            "Prediction of CGH: 69.15% Actual Outcome:  Negative\n",
            "Prediction of CGH: 28.10% Actual Outcome:  Negative\n",
            "Prediction of CGH: 19.77% Actual Outcome:  Postive\n",
            "Prediction of CGH: 69.15% Actual Outcome:  Negative\n",
            "Prediction of CGH: 44.87% Actual Outcome:  Negative\n",
            "Prediction of CGH: 0.19% Actual Outcome:  Negative\n",
            "Prediction of CGH: 76.22% Actual Outcome:  Postive\n",
            "Prediction of CGH: 35.09% Actual Outcome:  Postive\n",
            "Prediction of CGH: 31.66% Actual Outcome:  Negative\n",
            "Prediction of CGH: 41.19% Actual Outcome:  Negative\n",
            "Prediction of CGH: 35.58% Actual Outcome:  Negative\n",
            "Prediction of CGH: 84.82% Actual Outcome:  Postive\n",
            "Prediction of CGH: 66.67% Actual Outcome:  Negative\n",
            "Prediction of CGH: 71.26% Actual Outcome:  Postive\n",
            "Prediction of CGH: 90.20% Actual Outcome:  Negative\n",
            "Prediction of CGH: 40.02% Actual Outcome:  Negative\n",
            "Prediction of CGH: 23.80% Actual Outcome:  Negative\n",
            "Prediction of CGH: 65.69% Actual Outcome:  Negative\n",
            "Prediction of CGH: 92.57% Actual Outcome:  Negative\n",
            "Prediction of CGH: 48.24% Actual Outcome:  Negative\n",
            "Prediction of CGH: 40.80% Actual Outcome:  Negative\n",
            "Prediction of CGH: 60.00% Actual Outcome:  Negative\n",
            "Prediction of CGH: 53.12% Actual Outcome:  Negative\n",
            "Prediction of CGH: 30.96% Actual Outcome:  Negative\n",
            "Prediction of CGH: 43.64% Actual Outcome:  Negative\n",
            "Prediction of CGH: 48.67% Actual Outcome:  Postive\n",
            "Prediction of CGH: 0.97% Actual Outcome:  Postive\n",
            "Prediction of CGH: 35.06% Actual Outcome:  Postive\n",
            "Prediction of CGH: 96.58% Actual Outcome:  Negative\n",
            "Prediction of CGH: 33.30% Actual Outcome:  Negative\n",
            "Prediction of CGH: 47.66% Actual Outcome:  Postive\n",
            "Prediction of CGH: 3.92% Actual Outcome:  Negative\n",
            "Prediction of CGH: 20.59% Actual Outcome:  Postive\n",
            "Prediction of CGH: 82.07% Actual Outcome:  Postive\n",
            "Prediction of CGH: 0.89% Actual Outcome:  Negative\n",
            "Prediction of CGH: 33.28% Actual Outcome:  Negative\n",
            "Prediction of CGH: 1.95% Actual Outcome:  Negative\n",
            "Prediction of CGH: 24.55% Actual Outcome:  Negative\n",
            "Prediction of CGH: 0.60% Actual Outcome:  Negative\n",
            "Prediction of CGH: 11.15% Actual Outcome:  Negative\n",
            "Prediction of CGH: 48.90% Actual Outcome:  Negative\n",
            "Prediction of CGH: 6.73% Actual Outcome:  Postive\n",
            "Prediction of CGH: 1.04% Actual Outcome:  Negative\n",
            "Prediction of CGH: 42.94% Actual Outcome:  Postive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}